{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('C:/Users/anastasiia.verbitska/Desktop/Machine Learning/hw02/classification_params_example.json', 'r')\n",
    "example = json.load(f)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 13)\n",
    "cv = cross_val_score(lr, X_train, y_train, cv = 3, scoring = 'accuracy')\n",
    "print(cv)\n",
    "print(np.mean(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 13)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(lr.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(lr.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим лучшую модель исходя из заданного набора параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 13)\n",
    "params = {'C': np.arange(0.1, 10, 0.1), 'penalty':['l1','l2']}\n",
    "gscv = GridSearchCV(lr, params, cv = 3)\n",
    "\n",
    "cv = cross_val_score(gscv, X_train, y_train, cv = 3, scoring = 'accuracy')\n",
    "print(cv)\n",
    "print(np.mean(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 13)\n",
    "params = {'C': np.arange(0.1, 10, 0.1), 'penalty':['l1','l2']}\n",
    "gscv = GridSearchCV(lr, params, cv = 3)\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(gscv.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(gscv.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_estimator_.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gscv.best_estimator_.penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем результаты в .json файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {'C' : gscv.best_estimator_.C, 'penalty'  : gscv.best_estimator_.penalty, \n",
    "           'random_state' : gscv.best_estimator_.random_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('classification_params_result.json', 'w') as f:\n",
    "  json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load svm_impl_result.py\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "SVM_PARAMS_DICT = {\n",
    "    'C': 10.,\n",
    "    'random_state': 13,\n",
    "    'iters': 10000,\n",
    "    'batch_size': 100,\n",
    "    'step': 0.015\n",
    "}\n",
    "\n",
    "\n",
    "class MySVM(BaseEstimator):\n",
    "    def __init__(self, C, random_state, iters, batch_size, step):\n",
    "        self.C = C\n",
    "        self.random_state = random_state\n",
    "        self.iters = iters\n",
    "        self.batch_size = batch_size\n",
    "        self.step = step\n",
    "\n",
    "    # будем пользоваться этой функцией для подсчёта <w, x>\n",
    "    def __predict(self, X):\n",
    "        return np.dot(X, self.w) + self.w0\n",
    "\n",
    "    # sklearn нужно, чтобы predict возвращал классы, поэтому оборачиваем наш __predict в это\n",
    "    def predict(self, X):\n",
    "        res = self.__predict(X)\n",
    "        res[res > 0] = 1\n",
    "        res[res < 0] = 0\n",
    "        return res\n",
    "\n",
    "    # производная регуляризатора\n",
    "    def der_reg(self):\n",
    "        return 1. / self.C * self.w\n",
    "\n",
    "    # будем считать стохастический градиент не на одном элементе, а сразу на пачке (чтобы было эффективнее)\n",
    "    def der_loss(self, x, y):\n",
    "        # s.shape == (batch_size, features)\n",
    "        # y.shape == (batch_size,)\n",
    "\n",
    "        # считаем производную по каждой координате на каждом объекте\n",
    "        # TODO\n",
    "        M = self.__predict(x) * y.transpose()\n",
    "        func = lambda x: -1.0 if 1 - x > 0 else 0.0\n",
    "        vfunc = np.vectorize(func)\n",
    "        loss = vfunc(M)\n",
    "\n",
    "        # занулить производные там, где отступ > 1\n",
    "        # TODO\n",
    "        loss[M > 1] = 0\n",
    "\n",
    "        # для масштаба возвращаем средний градиент по пачке\n",
    "        # TODO\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # RandomState для воспроизводитмости\n",
    "        random_gen = np.random.RandomState(self.random_state)\n",
    "        \n",
    "        # получаем размерности матрицы\n",
    "        size, dim = X_train.shape\n",
    "        \n",
    "        # случайная начальная инициализация\n",
    "        self.w = random_gen.rand(dim)\n",
    "        self.w0 = random_gen.randn(1)\n",
    "\n",
    "        for i in range(self.iters):  \n",
    "            # берём случайный набор элементов\n",
    "            rand_indices = random_gen.choice(size, self.batch_size)\n",
    "            x = X_train[rand_indices]\n",
    "            y = y_train[rand_indices] * 2 - 1 # исходные метки классов это 0/1 а нам надо -1/1\n",
    "\n",
    "            # считаем производные\n",
    "            # TODO\n",
    "            grad = self.der_loss(x, y)\n",
    "\n",
    "            # обновляемся по антиградиенту\n",
    "            # TODO\n",
    "            self.w = self.w - self.step * (np.dot(y, x) * grad - self.der_reg())\n",
    "            self.w0 = self.w0 - self.step * np.dot(y, np.ones(100)) * grad\n",
    "\n",
    "        # метод fit для sklearn должен возвращать self\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
